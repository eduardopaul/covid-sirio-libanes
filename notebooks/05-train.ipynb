{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import redirect_stderr\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, make_scorer, precision_score, recall_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils.fixes import loguniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dict()\n",
    "train_data_path = Path('../data/train_data.pkl')\n",
    "with train_data_path.open('rb') as file:\n",
    "    train_data['in'] = pickle.load(file)\n",
    "\n",
    "test_data_path = Path('../data/test_data.pkl')\n",
    "with test_data_path.open('rb') as file:\n",
    "    test_data = pickle.load(file)\n",
    "\n",
    "groups_path = Path('../data/groups.json')\n",
    "with groups_path.open('r') as file:\n",
    "    groups = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed during the exploratory data analysis, there are several pre-processing steps that could be taken. This section defines those steps as functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_redundant_columns(df):\n",
    "    '''\n",
    "    Drop redundant columns from the ``DataFrame``.\n",
    "\n",
    "    Returns the ``DataFrame`` with the ``_diff`` and ``_diff_rel`` columns\n",
    "    removed.\n",
    "    '''\n",
    "    redundant_features = (\n",
    "        df.columns\n",
    "        .str.extract('(\\w+_diff(?:_rel)?(?:__.+)?)')\n",
    "        .squeeze()\n",
    "        .dropna()\n",
    "    )\n",
    "\n",
    "    df_ = df.drop(redundant_features, axis=1)\n",
    "\n",
    "    return df_\n",
    "\n",
    "\n",
    "def drop_duplicate_columns(df, groups=groups):\n",
    "    '''\n",
    "    Drop ``DataFrame``'s repeated columns.\n",
    "\n",
    "    Since the ``DataFrame`` only has duplicated columns in the ``labs``\n",
    "    category, they can be dropped directly.\n",
    "    '''\n",
    "    # Since some of the columns may have been dropped in a previous operation,\n",
    "    # it is necessary to get the intersection of ``groups['labs']`` with the\n",
    "    # columns present in ``df`` to avoid a ``KeyError``.\n",
    "    columns = df.columns.intersection(groups['labs'])\n",
    "\n",
    "    cols_to_drop = (\n",
    "        df.loc[:, columns]\n",
    "        .columns\n",
    "        .str.extract('(\\w+_(?:mean|median|min|diff|diff_rel)(?:__.+)?)')\n",
    "        .squeeze()\n",
    "        .dropna()\n",
    "    )\n",
    "\n",
    "    df_ = df.drop(cols_to_drop, axis=1)\n",
    "\n",
    "    return df_\n",
    "\n",
    "\n",
    "def impute_data(df):\n",
    "    '''\n",
    "    Impute missing data.\n",
    "\n",
    "    Fills ``DataFrame`` by each ``id`` group, using backwards and forwards\n",
    "    fill, in this order.\n",
    "    '''\n",
    "    df_ = (\n",
    "        df.groupby('id')\n",
    "        .transform(lambda col: col.bfill().ffill())\n",
    "    )\n",
    "\n",
    "    return df_\n",
    "\n",
    "def one_hot_encode(df):\n",
    "    '''\n",
    "    One-hot encode ``age_percentil`` column.\n",
    "\n",
    "    Returns ``DataFrame`` with the column ``age_percentil`` substituted by a\n",
    "    set of columns with its one-hot-encoded values.\n",
    "    '''\n",
    "    df_ = df.drop(['age_percentil'], axis=1)\n",
    "\n",
    "    dummies = pd.get_dummies(df['age_percentil'])\n",
    "    for col in dummies:\n",
    "        df_.insert(1, col, dummies[col])\n",
    "\n",
    "    return df_\n",
    "\n",
    "def reencode_icu(df):\n",
    "    '''\n",
    "    Return ``df`` with ``icu`` column reencoded.\n",
    "\n",
    "    The returned ``DataFrame``'s ``icu`` column is transformed such that\n",
    "    every row for a given patient is equal to 1 if the patient was\n",
    "    admitted at any point in time and 0 otherwise.\n",
    "    '''\n",
    "    df_ = df.copy()\n",
    "\n",
    "    df_.loc[:, 'icu'] = (\n",
    "        df_.loc[:, 'icu']\n",
    "        .groupby('id')\n",
    "        .transform('max')\n",
    "    )\n",
    "\n",
    "    return df_\n",
    "\n",
    "\n",
    "def process_rows(df, how='every_row', groups=groups):\n",
    "    '''\n",
    "    Process ``DataFrame`` according to discussion in the EDA.\n",
    "    '''\n",
    "    df_ = df.copy()\n",
    "\n",
    "    df_ = reencode_icu(df_)\n",
    "\n",
    "    if how == 'every_row':\n",
    "        # Nothing has to be done in this case.\n",
    "        df_ = df_\n",
    "\n",
    "    elif how == 'first_window':\n",
    "        df_ = df_.loc[(slice(None), '0-2'), :]\n",
    "\n",
    "    elif how == 'aggregate':\n",
    "        # The features in ``labs`` and ``vitals`` will be aggregated by ``mean``.\n",
    "        features_to_agg_by_mean = groups['labs'] + groups['vitals']\n",
    "        # All other features will be aggregated by ``max``.\n",
    "        features_to_agg_by_max = df_.columns.difference(features_to_agg_by_mean)\n",
    "\n",
    "        agg_funcs = {\n",
    "            feature: 'max'\n",
    "            for feature in features_to_agg_by_max\n",
    "            if feature in df_.columns\n",
    "        }\n",
    "\n",
    "        agg_funcs.update({\n",
    "            feature: 'mean'\n",
    "            for feature in features_to_agg_by_mean\n",
    "            if feature in df_.columns\n",
    "        })\n",
    "\n",
    "        df_ = (\n",
    "            df_.groupby('id')\n",
    "            .agg(agg_funcs)\n",
    "            # The method ``loc`` sorts the columns as they were coming in.\n",
    "            .loc[:, df_.columns]\n",
    "        )\n",
    "\n",
    "    elif how == 'pivot':\n",
    "        # Only ``labs`` and ``vitals`` have different values for the distinct\n",
    "        # time windows.  The intersection prevents a ``KeyError`` due to\n",
    "        # dropped columns.\n",
    "        features_to_pivot = df_.columns.intersection(groups['labs']+groups['vitals'])\n",
    "\n",
    "        pivoted_df = df_[features_to_pivot].unstack('window')\n",
    "\n",
    "        # Flattens the ``MultiIndex`` to a single level.\n",
    "        pivoted_df.columns = pivoted_df.columns.map(\n",
    "            lambda multiindex_tuple: '__'.join(multiindex_tuple).replace('-', '_')\n",
    "        )\n",
    "\n",
    "        # Reconstructs the whole ``DataFrame`` by concatenating with the\n",
    "        # remaining features aggregated.\n",
    "        df_ = pd.concat(\n",
    "            [\n",
    "                df_[groups['demographics']+groups['comorbidities']].groupby('id').max(),\n",
    "                pivoted_df,\n",
    "                df_['icu'].groupby('id').first(),\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        print('Invalid option passed to \"how\" parameter.')\n",
    "\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_on_first_window(y_true, y_pred):\n",
    "    '''\n",
    "    Get score on first window.\n",
    "\n",
    "    Returns the recall score the model has calculated considering just the first\n",
    "    time window.\n",
    "    '''\n",
    "    # Since there are 5 time windows, take every 5 rows.\n",
    "    score_first_window = recall_score(y_true[::5], y_pred[::5])\n",
    "\n",
    "    return score_first_window\n",
    "\n",
    "\n",
    "def train_models(train_data, models, preprocessings, n_iter=5):\n",
    "    '''\n",
    "    Train given models on passed data.\n",
    "\n",
    "    Constructs a ``Pipeline`` and trains it through a ``RandomizedSearchCV`` for\n",
    "    every combination of pre-processing and model.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    search_results : ``pandas.DataFrame``\n",
    "        Models and their results, ordered by performance.\n",
    "    best_models : ``dict``\n",
    "        Best ``sklearn`` estimator for each trained model class.\n",
    "    '''\n",
    "    search_results = pd.DataFrame()\n",
    "    best_models = {\n",
    "        'every_row': dict(),\n",
    "        'first_window': dict(),\n",
    "        'aggregate': dict(),\n",
    "    }\n",
    "\n",
    "    for model_name, model_dict in models.items():\n",
    "        for preprocessing in preprocessings:\n",
    "            X = train_data[preprocessing].drop(['icu'], axis=1)\n",
    "            y = train_data[preprocessing]['icu']\n",
    "\n",
    "            pipeline = make_pipeline(\n",
    "                SimpleImputer(),\n",
    "                model_dict['model'],\n",
    "            )\n",
    "\n",
    "            search = RandomizedSearchCV(\n",
    "                pipeline,\n",
    "                param_distributions=model_dict['search_params'],\n",
    "                n_iter=n_iter,\n",
    "                random_state=2937103,\n",
    "            )\n",
    "            \n",
    "            # Sometimes sklearn appears to raise a ValueError instead of a\n",
    "            # warning when an impossible combination of parameters is supplied\n",
    "            # to RandomizedSearchCV. The try-except block prevents the procedure\n",
    "            # from being stopped.\n",
    "            try:\n",
    "                search.fit(X, y)\n",
    "            except ValueError as error:\n",
    "                print(error, file=sys.stderr)\n",
    "            else:\n",
    "                results = pd.DataFrame(search.cv_results_)\n",
    "                results.insert(0, 'pre-processing', preprocessing)\n",
    "                results.insert(1, 'model', model_name)\n",
    "\n",
    "                search_results = search_results.append(results, ignore_index=True)\n",
    "\n",
    "            best_models[preprocessing][model_name] = search.best_estimator_\n",
    "\n",
    "    search_results = (\n",
    "        search_results\n",
    "        .sort_values(by='mean_test_score', ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    return search_results, best_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before passing the *train_data* to ``scikit-learn``, it has to go through the pre-processing steps that were discussed during the EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['preprocessed'] = (\n",
    "    train_data['in']\n",
    "    .pipe(drop_redundant_columns)\n",
    "    .pipe(drop_duplicate_columns)\n",
    "    .pipe(impute_data)\n",
    "    .pipe(one_hot_encode)\n",
    "    .pipe(reencode_icu)\n",
    ")\n",
    "\n",
    "preprocessings = ['every_row', 'first_window', 'aggregate']\n",
    "for preprocessing in preprocessings:\n",
    "    train_data[preprocessing] = process_rows(train_data['preprocessed'], how=preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *test_data* also goes through all of the pre-processing, but the rows processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = (\n",
    "    test_data\n",
    "    .pipe(drop_redundant_columns)\n",
    "    .pipe(drop_duplicate_columns)\n",
    "    .pipe(impute_data)\n",
    "    .pipe(one_hot_encode)\n",
    "    .pipe(reencode_icu)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running a ``RandomizedSearchCV`` requires the definition of a set of parameters to be explored. As many models will be tried, a dictionary containing the model objects and the parameters is defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LogisticRegression': {\n",
    "        'model': LogisticRegression(max_iter=10000),\n",
    "        'search_params': {\n",
    "            'logisticregression__penalty': ['l1', 'l2'],\n",
    "            'logisticregression__C': loguniform(1e-1, 1e3),\n",
    "            'logisticregression__solver': ['lbfgs', 'liblinear', 'sag'],\n",
    "        },\n",
    "    },\n",
    "    'DecisionTreeClassifier': {\n",
    "        'model': DecisionTreeClassifier(),\n",
    "        'search_params': {\n",
    "            'decisiontreeclassifier__criterion': ['gini', 'entropy'],\n",
    "            'decisiontreeclassifier__splitter': ['best', 'random'],\n",
    "            'decisiontreeclassifier__max_depth': range(2, 10),\n",
    "        },\n",
    "    },\n",
    "    'KNeighborsClassifier': {\n",
    "        'model': KNeighborsClassifier(),\n",
    "        'search_params': {\n",
    "            'kneighborsclassifier__n_neighbors': range(2,20),\n",
    "            'kneighborsclassifier__weights': ['uniform', 'distance'],\n",
    "            'kneighborsclassifier__p': [1, 2],\n",
    "        },\n",
    "    },\n",
    "    'LinearSVC': {\n",
    "        'model': LinearSVC(max_iter=10000),\n",
    "        'search_params': {\n",
    "            'linearsvc__penalty': ['l1', 'l2'],\n",
    "            'linearsvc__loss': ['hinge', 'squared_hinge'],\n",
    "            'linearsvc__C': loguniform(1e-1, 1e3),\n",
    "        },\n",
    "    },\n",
    "    'RandomForestClassifier': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'search_params': {\n",
    "            'randomforestclassifier__criterion': ['gini', 'entropy'],\n",
    "            'randomforestclassifier__n_estimators': [50, 100, 150, 200],\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally models are created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid filling up the screen when parameters are invalid, all warnings are\n",
    "# redirected to an external file.\n",
    "sklearn_warnings_path = Path('../sklearn-warnings.txt')\n",
    "with sklearn_warnings_path.open('w') as file:\n",
    "    with redirect_stderr(file):\n",
    "\n",
    "        search_results, best_models = train_models(\n",
    "            train_data,\n",
    "            models,\n",
    "            preprocessings,\n",
    "            # ['first_window'],\n",
    "            n_iter=4,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results[['pre-processing', 'model', 'mean_test_score']].iloc[:10, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's informative to see a table with a summary of the models' performances on the test set that was held out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pre-processing</th>\n      <th>model</th>\n      <th>mean_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>aggregate</td>\n      <td>RandomForestClassifier</td>\n      <td>0.842105</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>aggregate</td>\n      <td>RandomForestClassifier</td>\n      <td>0.838596</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>aggregate</td>\n      <td>RandomForestClassifier</td>\n      <td>0.838596</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>aggregate</td>\n      <td>RandomForestClassifier</td>\n      <td>0.835088</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>aggregate</td>\n      <td>LinearSVC</td>\n      <td>0.821053</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>aggregate</td>\n      <td>LogisticRegression</td>\n      <td>0.817544</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>aggregate</td>\n      <td>DecisionTreeClassifier</td>\n      <td>0.814035</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>every_row</td>\n      <td>RandomForestClassifier</td>\n      <td>0.808421</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>every_row</td>\n      <td>RandomForestClassifier</td>\n      <td>0.807719</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>aggregate</td>\n      <td>LogisticRegression</td>\n      <td>0.807018</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "  pre-processing                   model  mean_test_score\n0      aggregate  RandomForestClassifier         0.842105\n1      aggregate  RandomForestClassifier         0.838596\n2      aggregate  RandomForestClassifier         0.838596\n3      aggregate  RandomForestClassifier         0.835088\n4      aggregate               LinearSVC         0.821053\n5      aggregate      LogisticRegression         0.817544\n6      aggregate  DecisionTreeClassifier         0.814035\n7      every_row  RandomForestClassifier         0.808421\n8      every_row  RandomForestClassifier         0.807719\n9      aggregate      LogisticRegression         0.807018"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X = test_data.drop(['icu'], axis=1)\n",
    "test_y = test_data['icu']\n",
    "\n",
    "time_windows = ['0-2', '2-4', '4-6', '6-12', 'above_12']\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for preprocessing, model_dict in best_models.items():\n",
    "    for model_name, model in model_dict.items():\n",
    "        predictions = pd.Series(\n",
    "            model.predict(test_X),\n",
    "            index=test_y.index,\n",
    "            name='prediction'\n",
    "        )\n",
    "\n",
    "        for time_window in time_windows:\n",
    "            rows_to_consider = (slice(None), time_window) \n",
    "            test = test_y[rows_to_consider]\n",
    "            pred = predictions[rows_to_consider]\n",
    "            df = (\n",
    "                df\n",
    "                .append(\n",
    "                    {\n",
    "                        'pre-processing': preprocessing,\n",
    "                        'model': model_name,\n",
    "                        'window': time_window,\n",
    "                        'accuracy': accuracy_score(test, pred),\n",
    "                        'precision': precision_score(test, pred),\n",
    "                        'recall': recall_score(test, pred),\n",
    "                    },\n",
    "                    ignore_index=True,\n",
    "                )\n",
    "            )\n",
    "\n",
    "df = df.set_index(['model', 'pre-processing', 'window']).unstack(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking just at the ``recall`` and sorting by performance on the first time window, it can be seen that models trained using only the first window performed the best. Especially so are the ``RandomForestClassifier`` and the ``LogisticRegression``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>window</th>\n      <th>0-2</th>\n      <th>2-4</th>\n      <th>4-6</th>\n      <th>6-12</th>\n      <th>above_12</th>\n    </tr>\n    <tr>\n      <th>model</th>\n      <th>pre-processing</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>RandomForestClassifier</th>\n      <th>first_window</th>\n      <td>0.784314</td>\n      <td>0.745098</td>\n      <td>0.784314</td>\n      <td>0.784314</td>\n      <td>0.843137</td>\n    </tr>\n    <tr>\n      <th>LogisticRegression</th>\n      <th>first_window</th>\n      <td>0.745098</td>\n      <td>0.666667</td>\n      <td>0.784314</td>\n      <td>0.882353</td>\n      <td>0.960784</td>\n    </tr>\n    <tr>\n      <th>RandomForestClassifier</th>\n      <th>every_row</th>\n      <td>0.745098</td>\n      <td>0.764706</td>\n      <td>0.862745</td>\n      <td>0.882353</td>\n      <td>0.901961</td>\n    </tr>\n    <tr>\n      <th>LinearSVC</th>\n      <th>first_window</th>\n      <td>0.725490</td>\n      <td>0.647059</td>\n      <td>0.745098</td>\n      <td>0.862745</td>\n      <td>0.980392</td>\n    </tr>\n    <tr>\n      <th>DecisionTreeClassifier</th>\n      <th>first_window</th>\n      <td>0.705882</td>\n      <td>0.588235</td>\n      <td>0.686275</td>\n      <td>0.745098</td>\n      <td>0.705882</td>\n    </tr>\n    <tr>\n      <th>LogisticRegression</th>\n      <th>every_row</th>\n      <td>0.686275</td>\n      <td>0.666667</td>\n      <td>0.823529</td>\n      <td>0.862745</td>\n      <td>0.862745</td>\n    </tr>\n    <tr>\n      <th>DecisionTreeClassifier</th>\n      <th>every_row</th>\n      <td>0.666667</td>\n      <td>0.666667</td>\n      <td>0.745098</td>\n      <td>0.764706</td>\n      <td>0.764706</td>\n    </tr>\n    <tr>\n      <th>LinearSVC</th>\n      <th>every_row</th>\n      <td>0.666667</td>\n      <td>0.588235</td>\n      <td>0.803922</td>\n      <td>0.862745</td>\n      <td>0.843137</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">KNeighborsClassifier</th>\n      <th>first_window</th>\n      <td>0.529412</td>\n      <td>0.588235</td>\n      <td>0.784314</td>\n      <td>0.784314</td>\n      <td>0.784314</td>\n    </tr>\n    <tr>\n      <th>aggregate</th>\n      <td>0.470588</td>\n      <td>0.568627</td>\n      <td>0.725490</td>\n      <td>0.784314</td>\n      <td>0.823529</td>\n    </tr>\n    <tr>\n      <th>RandomForestClassifier</th>\n      <th>aggregate</th>\n      <td>0.450980</td>\n      <td>0.450980</td>\n      <td>0.705882</td>\n      <td>0.803922</td>\n      <td>0.823529</td>\n    </tr>\n    <tr>\n      <th>LinearSVC</th>\n      <th>aggregate</th>\n      <td>0.333333</td>\n      <td>0.392157</td>\n      <td>0.627451</td>\n      <td>0.686275</td>\n      <td>0.980392</td>\n    </tr>\n    <tr>\n      <th>DecisionTreeClassifier</th>\n      <th>aggregate</th>\n      <td>0.313725</td>\n      <td>0.372549</td>\n      <td>0.372549</td>\n      <td>0.588235</td>\n      <td>0.843137</td>\n    </tr>\n    <tr>\n      <th>LogisticRegression</th>\n      <th>aggregate</th>\n      <td>0.294118</td>\n      <td>0.392157</td>\n      <td>0.647059</td>\n      <td>0.745098</td>\n      <td>0.980392</td>\n    </tr>\n    <tr>\n      <th>KNeighborsClassifier</th>\n      <th>every_row</th>\n      <td>0.274510</td>\n      <td>0.392157</td>\n      <td>0.549020</td>\n      <td>0.549020</td>\n      <td>0.784314</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "window                                      0-2       2-4       4-6      6-12  \\\nmodel                  pre-processing                                           \nRandomForestClassifier first_window    0.784314  0.745098  0.784314  0.784314   \nLogisticRegression     first_window    0.745098  0.666667  0.784314  0.882353   \nRandomForestClassifier every_row       0.745098  0.764706  0.862745  0.882353   \nLinearSVC              first_window    0.725490  0.647059  0.745098  0.862745   \nDecisionTreeClassifier first_window    0.705882  0.588235  0.686275  0.745098   \nLogisticRegression     every_row       0.686275  0.666667  0.823529  0.862745   \nDecisionTreeClassifier every_row       0.666667  0.666667  0.745098  0.764706   \nLinearSVC              every_row       0.666667  0.588235  0.803922  0.862745   \nKNeighborsClassifier   first_window    0.529412  0.588235  0.784314  0.784314   \n                       aggregate       0.470588  0.568627  0.725490  0.784314   \nRandomForestClassifier aggregate       0.450980  0.450980  0.705882  0.803922   \nLinearSVC              aggregate       0.333333  0.392157  0.627451  0.686275   \nDecisionTreeClassifier aggregate       0.313725  0.372549  0.372549  0.588235   \nLogisticRegression     aggregate       0.294118  0.392157  0.647059  0.745098   \nKNeighborsClassifier   every_row       0.274510  0.392157  0.549020  0.549020   \n\nwindow                                 above_12  \nmodel                  pre-processing            \nRandomForestClassifier first_window    0.843137  \nLogisticRegression     first_window    0.960784  \nRandomForestClassifier every_row       0.901961  \nLinearSVC              first_window    0.980392  \nDecisionTreeClassifier first_window    0.705882  \nLogisticRegression     every_row       0.862745  \nDecisionTreeClassifier every_row       0.764706  \nLinearSVC              every_row       0.843137  \nKNeighborsClassifier   first_window    0.784314  \n                       aggregate       0.823529  \nRandomForestClassifier aggregate       0.823529  \nLinearSVC              aggregate       0.980392  \nDecisionTreeClassifier aggregate       0.843137  \nLogisticRegression     aggregate       0.980392  \nKNeighborsClassifier   every_row       0.784314  "
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['recall'].sort_values(by='0-2', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking those two best performing models, a table showing cumulative probability of prediction as a function of time window is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance(preprocessing, model):\n",
    "    '''\n",
    "    '''\n",
    "    predictions = pd.Series(\n",
    "        best_models[preprocessing][model].predict(test_X),\n",
    "        name='predictions',\n",
    "        index=test_y.index,\n",
    "    )\n",
    "\n",
    "    admitted_patients = test_y.groupby('id').filter(lambda s: s.max() == 1)\n",
    "\n",
    "    admitted_patients_predictions = predictions.reindex_like(admitted_patients).to_frame()\n",
    "\n",
    "    def get_window_of_prediction(group):\n",
    "        from numpy import nan\n",
    "        window = group.idxmax()\n",
    "\n",
    "        try:\n",
    "            window = window[1]\n",
    "        except TypeError:\n",
    "            window = nan\n",
    "\n",
    "        return window\n",
    "\n",
    "    windows = (\n",
    "        admitted_patients_predictions[admitted_patients_predictions == 1]\n",
    "        .groupby('id')\n",
    "        .agg(\n",
    "            window_of_prediction=('predictions', get_window_of_prediction)\n",
    "        )\n",
    "        .squeeze()\n",
    "    )\n",
    "\n",
    "    cumulative_prob_of_prediction = windows.value_counts(normalize=True, dropna=False).sort_index().cumsum().rename(model)\n",
    "\n",
    "    return cumulative_prob_of_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the ``RandomForestClassifier`` is more capable of getting correct prediction of admission during the first time window, it can be seen that the ``LogisticRegression`` takes over for later time windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RandomForestClassifier</th>\n      <th>LogisticRegression</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0-2</th>\n      <td>0.784314</td>\n      <td>0.745098</td>\n    </tr>\n    <tr>\n      <th>2-4</th>\n      <td>0.823529</td>\n      <td>0.784314</td>\n    </tr>\n    <tr>\n      <th>4-6</th>\n      <td>0.941176</td>\n      <td>0.941176</td>\n    </tr>\n    <tr>\n      <th>6-12</th>\n      <td>NaN</td>\n      <td>0.960784</td>\n    </tr>\n    <tr>\n      <th>above_12</th>\n      <td>NaN</td>\n      <td>0.980392</td>\n    </tr>\n    <tr>\n      <th>NaN</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "          RandomForestClassifier  LogisticRegression\n0-2                     0.784314            0.745098\n2-4                     0.823529            0.784314\n4-6                     0.941176            0.941176\n6-12                         NaN            0.960784\nabove_12                     NaN            0.980392\nNaN                     1.000000            1.000000"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(\n",
    "    [\n",
    "        get_performance('first_window', 'RandomForestClassifier'),\n",
    "        get_performance('first_window', 'LogisticRegression'),\n",
    "    ],\n",
    "    axis=1,\n",
    ").sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several different models were trained and evaluated. For each of those models, several distinct pre-processing procedures were attempted, namely, \n",
    "- taking only the first time window for each patient,\n",
    "- aggregating all time windows into one,\n",
    "- using every row of the dataset as if corresponding to distinct patients.\n",
    "\n",
    "The performances were evaluated based on the recall, which is the probability of correctly guessing admission.\n",
    "The two best performing models were a ``RandomForestClassifier`` and a ``LogisticRegression``, both trained on just the data for each patient's first time window."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit ('covid19': conda)",
   "name": "python392jvsc74a57bd001df4937fe10f0b782b7cc58276db2d8e1dd1e5af07b5f89f2331fd46a13fc9e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}